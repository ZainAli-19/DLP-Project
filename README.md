# DLP Project - Solar Energy Forecasting  
**Roll No:** 21K-4870  
**Section:** BCS-DLP 8B  

## ğŸ“˜ Project Title  
**Deep Learning-Based Forecasting of Solar Energy Generation Using Weather Data**

---

## ğŸ§  Project Description  
This project aims to forecast solar energy output using deep learning models trained on hourly weather and solar generation data. The models compared include:  
- **LSTM (Long Short-Term Memory)**
- **GRU (Gated Recurrent Unit)**
- **Transformer Encoder**

All models predict hourly solar output using the past 24 hours of weather and system data.

---

## ğŸ—ƒï¸ Dataset  
- **Solar Generation**: Hourly kWh values (2022â€“2024) from multiple solar sites  
- **Weather Data**: Hourly temperature, humidity, wind speed, etc.  
- **Merged on**: `Year`, `Month`, `Hour`

---

## ğŸ§ª Models Overview

| Model       | MAE     | RMSE     | RÂ²     | MAPE (%)     |
|-------------|---------|----------|--------|--------------|
| **LSTM**     | 16,868  | 29,633   | 0.3672 | 4.81         |
| **GRU**      | 11,296  | 19,406   | 0.7286 | 465.37       |
| **Transformer** | 20,191  | 30,871   | 0.3132 | 1,515.82     |

- **Best RÂ² and RMSE**: GRU  
- **Most stable MAPE**: LSTM  
- **Transformer** suffered from MAPE distortion due to zero or low actual values.

---

## ğŸ§° Tools & Libraries  
- Python 3.11  
- TensorFlow / Keras  
- Scikit-learn  
- Pandas / NumPy  
- Matplotlib  
- Google Colab (12 GB RAM, TPU runtime)

---

## âš™ï¸ Technical Details  
- Input: Sliding window of 24-hour sequences  
- Normalization: `MinMaxScaler`  
- Optimizer: `Adam`  
- Loss: `Mean Squared Error`  
- Learning Rate Scheduler: `ReduceLROnPlateau`  
- EarlyStopping (GRU and Transformer)

---

## ğŸ“‚ Files Included  
- `DLP_Report.pdf` â€“ Final formatted scientific report  
- `README.md` â€“ This file  
- Source code (optional: include notebooks or `.py` scripts)

---

## ğŸ“ˆ Future Improvements  
- Handle low-output periods to stabilize MAPE  
- Incorporate external factors (holidays, sunlight hours)  
- Tune Transformer further with positional embeddings  
- Try hybrid CNN-RNN architectures

---

## âœï¸ Author  
**Name:** Zain Ali Siddiqui  
**Roll No:** 21K-4870  
**Course:** Deep Learning Project (BCS-DLP 8B)  
